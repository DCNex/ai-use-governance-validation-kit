### 目的說明
本章節定義金融業運用 AI / LLM 之 **可用範疇** 與 **不可逾越之紅線**，
並依據金管會《金融業運用人工智慧（AI）指引》進行設計。

整體設計採取 **風險基礎與比例原則**，
在促進創新之同時，確保責任歸屬、客戶權益及金融穩定。 :contentReference[oaicite:5]{index=5}

---

### 納入範疇（In-scope）
下列 AI 應用原則上可納入，惟須依風險分級進行驗證與監控：

- 內部生產力工具（如摘要、文件輔助、知識查詢）
- 具備 **人工覆核與最終責任** 的決策輔助系統
- 已揭露並提供替代方案的客服輔助應用
- 不構成全自動對客決策之風險分析與異常偵測

> 所有納入範疇之應用，均須通過使用情境申請、驗證及監控流程。

---

### 禁止情境／紅線（Out-of-scope）
除經符合法規之試辦或沙盒機制核准外，下列情境原則上禁止：

1. **未具實質人工覆核**，即直接影響客戶權益或義務之全自動決策
2. 超出核准範圍使用 **個人資料或敏感客戶資訊**
3. 將 AI 輸出視為最終裁量，用於授信、定價、理賠或資格認定
4. 欠缺充分測試、稽核留痕或可解釋性之 AI 系統
5. 未揭露 AI 使用，或未提供合理說明與替代方案之對客應用

上述紅線反映指引對 **客戶保護、問責與透明性** 的核心要求。 

---

### 風險分級原則
AI 使用情境應依風險基礎進行分級：

- **高風險**  
  - 直接影響客戶權益  
  - 需正式核准、人工覆核（HITL）、強化驗證與持續監控

- **中風險**  
  - 間接影響客戶或內部決策輔助  
  - 需驗證、留痕與定期檢視

- **低風險**  
  - 僅限內部使用、不影響客戶  
  - 需基本控管與使用監測

風險分級用以決定 **控管深度**，而非是否可使用 AI。 :contentReference[oaicite:7]{index=7}

---

### 生成式 AI 特別限制
針對生成式 AI：

- 其輸出 **不得視為具權威性或最終決策**
- 高風險情境仍須由專業人員負責判斷
- 訓練與提示資料須遵循資料分級與隱私規範
- 應持續記錄與監控模型限制與潛在風險

此設計對齊指引對生成式 AI「工具性」之定位。 :contentReference[oaicite:8]{index=8}

---

### 取捨與例外（Trade-offs & Exceptions）
- **效率 vs. 風險控管**：中風險情境得有限度先行使用，
  但須於期限內補齊驗證與留痕。
- **業務例外**：任何例外須由產品負責人與法遵共同核准，
  並設定適用期限與回溯機制。
- **不可妥協底線**：涉及隱私、客戶權益或失控自動化時，
  應立即中止並升級處理。

---
